{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from gensim.models import word2vec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing plots with style \n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "rcParams['lines.linewidth'] = 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入文字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集自維基百科\n",
    "with open(\"data/text/ref_text_tw.txt\", \"r\", encoding=\"utf-8\") as content:\n",
    "    document_list = [line.strip().replace(' ', '') for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['美希迪波路治一般稱作波路治，生於達爾貝達，摩洛哥職業足球運動員，現效力於美國職業足球大聯盟球會科羅拉多急流。', '羅利科隆出生於紐西蘭北島東北部吉斯伯恩，是一名英式足球足球運動員，司職前鋒前鋒，現時效力英甲球會斯坎索普聯足球俱樂部斯肯索普。', '他的機器實際上是在美國人口調查局的合約下完成的，製成後被用於1890年美國人口普查，普查工作因此得以在一年之內完成。', '石崎傳蔵，超級人瑞，曾是日本史上最年長男性。', '施世範，施琅第八子，襲封靖海侯。']\n",
      "total document num: 33868\n"
     ]
    }
   ],
   "source": [
    "print(document_list[:5])\n",
    "print(\"total document num: {}\".format(len(document_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結巴分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/mark/Documents/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.uf13363f31a3360411b43fe8e84af1634.cache\n",
      "Loading model cost 1.227 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 用來存放分詞後的結果\n",
    "preprocessed_documents = []\n",
    "# stopword\n",
    "with open(\"data/jieba_dict/stopwords.txt\") as stop_words:\n",
    "    stop_word_list = [stop_word.strip() for stop_word in stop_words]\n",
    "# 支援繁體中文較好的詞庫\n",
    "jieba.set_dictionary(\"data/jieba_dict/dict.txt.big\")\n",
    "for document in document_list:\n",
    "    preprocessed_document = list(jieba.cut(document))\n",
    "    preprocessed_documents.append(preprocessed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['美希迪波',\n",
       "  '路治',\n",
       "  '一般',\n",
       "  '稱作',\n",
       "  '波路治',\n",
       "  '，',\n",
       "  '生於',\n",
       "  '達爾貝',\n",
       "  '達',\n",
       "  '，',\n",
       "  '摩洛哥',\n",
       "  '職業',\n",
       "  '足球',\n",
       "  '運動員',\n",
       "  '，',\n",
       "  '現',\n",
       "  '效力',\n",
       "  '於',\n",
       "  '美國',\n",
       "  '職業',\n",
       "  '足球',\n",
       "  '大',\n",
       "  '聯盟',\n",
       "  '球會',\n",
       "  '科羅拉多',\n",
       "  '急流',\n",
       "  '。'],\n",
       " ['羅利',\n",
       "  '科隆',\n",
       "  '出',\n",
       "  '生於',\n",
       "  '紐西蘭',\n",
       "  '北島',\n",
       "  '東北部',\n",
       "  '吉斯',\n",
       "  '伯恩',\n",
       "  '，',\n",
       "  '是',\n",
       "  '一名',\n",
       "  '英式足球',\n",
       "  '足球',\n",
       "  '運動員',\n",
       "  '，',\n",
       "  '司職',\n",
       "  '前鋒',\n",
       "  '前鋒',\n",
       "  '，',\n",
       "  '現時',\n",
       "  '效力',\n",
       "  '英甲',\n",
       "  '球會',\n",
       "  '斯坎索',\n",
       "  '普聯',\n",
       "  '足球',\n",
       "  '俱樂部',\n",
       "  '斯肯',\n",
       "  '索普',\n",
       "  '。'],\n",
       " ['他',\n",
       "  '的',\n",
       "  '機器',\n",
       "  '實際上',\n",
       "  '是',\n",
       "  '在',\n",
       "  '美國',\n",
       "  '人口',\n",
       "  '調查局',\n",
       "  '的',\n",
       "  '合約',\n",
       "  '下',\n",
       "  '完成',\n",
       "  '的',\n",
       "  '，',\n",
       "  '製成',\n",
       "  '後',\n",
       "  '被',\n",
       "  '用於',\n",
       "  '1890',\n",
       "  '年',\n",
       "  '美國',\n",
       "  '人口普查',\n",
       "  '，',\n",
       "  '普查',\n",
       "  '工作',\n",
       "  '因此',\n",
       "  '得以',\n",
       "  '在',\n",
       "  '一年',\n",
       "  '之內',\n",
       "  '完成',\n",
       "  '。'],\n",
       " ['石崎傳',\n",
       "  '蔵',\n",
       "  '，',\n",
       "  '超級',\n",
       "  '人瑞',\n",
       "  '，',\n",
       "  '曾',\n",
       "  '是',\n",
       "  '日本',\n",
       "  '史上',\n",
       "  '最',\n",
       "  '年長',\n",
       "  '男性',\n",
       "  '。'],\n",
       " ['施世範', '，', '施琅', '第八', '子', '，', '襲封', '靖海侯', '。']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此即為分詞處理好的 corpus\n",
    "preprocessed_documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 word2vec 訓練詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(preprocessed_documents, min_count=1, window=10, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/tensorflow/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('中國國民黨', 0.9659200310707092),\n",
       " ('行政院長', 0.946959912776947),\n",
       " ('嚴家淦', 0.9464354515075684),\n",
       " ('陳水扁', 0.9446552991867065),\n",
       " ('黨內', 0.9390124678611755),\n",
       " ('李光耀', 0.938780665397644),\n",
       " ('中央委員會', 0.9379827380180359),\n",
       " ('尤索夫', 0.9375807046890259),\n",
       " ('朝鮮勞動黨', 0.9359132647514343),\n",
       " ('第一夫人', 0.9350582361221313),\n",
       " ('副委員長', 0.932766318321228),\n",
       " ('辦公室', 0.9327172040939331),\n",
       " ('中央政治局', 0.9323389530181885),\n",
       " ('李顯龍', 0.9308685064315796),\n",
       " ('委員長', 0.9298253655433655),\n",
       " ('連戰', 0.9284915328025818),\n",
       " ('鄧樸方', 0.9271532297134399),\n",
       " ('中華人民共和國國務院', 0.9269112348556519),\n",
       " ('訪華', 0.9266548156738281),\n",
       " ('古蹟', 0.9263201355934143),\n",
       " ('立法委員', 0.9259499907493591),\n",
       " ('胡錦濤', 0.9239287972450256),\n",
       " ('開幕', 0.9237228631973267),\n",
       " ('國務院', 0.9223554134368896),\n",
       " ('中共中央政治局', 0.9216533899307251),\n",
       " ('總統府', 0.9210458993911743),\n",
       " ('習近平', 0.9210121631622314),\n",
       " ('溫家寶', 0.9209234118461609),\n",
       " ('父親節', 0.9205612540245056),\n",
       " ('鄧小平', 0.919984757900238),\n",
       " ('偕', 0.919459879398346),\n",
       " ('楊尚昆', 0.9181934595108032),\n",
       " ('伉儷', 0.9179744720458984),\n",
       " ('壹', 0.9174838066101074),\n",
       " ('中央書記處', 0.916543185710907),\n",
       " ('薄熙來', 0.9165102243423462),\n",
       " ('政治局', 0.9159795641899109),\n",
       " ('林文慶', 0.9159444570541382),\n",
       " ('朝鮮人民軍', 0.9159385561943054),\n",
       " ('臺灣省', 0.9157949686050415),\n",
       " ('立法院', 0.915604829788208),\n",
       " ('宋楚瑜', 0.9150674939155579),\n",
       " ('第十七屆', 0.9136888980865479),\n",
       " ('財政部長', 0.9124864339828491),\n",
       " ('黨員', 0.9122772216796875),\n",
       " ('民進黨', 0.911088228225708),\n",
       " ('金門縣', 0.9110350608825684),\n",
       " ('習仲勳', 0.9109275937080383),\n",
       " ('楚青', 0.9106075167655945),\n",
       " ('周美青', 0.9091971516609192)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"李登輝\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/tensorflow/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('王雅琦', 0.9727765321731567),\n",
       " ('吳江', 0.9668613076210022),\n",
       " ('齊橋橋', 0.9624319672584534),\n",
       " ('宣萱', 0.9621230363845825),\n",
       " ('漫畫家', 0.961767852306366),\n",
       " ('莉莉', 0.9616739749908447),\n",
       " ('陳小藝', 0.9615285396575928),\n",
       " ('蔡天鐸', 0.9615163803100586),\n",
       " ('林翠', 0.961431622505188),\n",
       " ('曾國祥', 0.9607008695602417),\n",
       " ('喜劇演員', 0.9590493440628052),\n",
       " ('雲林縣', 0.958836019039154),\n",
       " ('節目主持', 0.9576021432876587),\n",
       " ('女藝員', 0.9572699069976807),\n",
       " ('顧正秋', 0.9570175409317017),\n",
       " ('鄭文堂', 0.9567718505859375),\n",
       " ('蘇州市', 0.9563143253326416),\n",
       " ('謝賢之子', 0.9562386274337769),\n",
       " ('餅店', 0.956059992313385),\n",
       " ('柯宇綸', 0.9560527801513672),\n",
       " ('曾懿貞', 0.9559885263442993),\n",
       " ('林子祥', 0.9558733701705933),\n",
       " ('郭鶴年', 0.9551891088485718),\n",
       " ('古裝劇', 0.9545445442199707),\n",
       " ('工旦行', 0.9544399976730347),\n",
       " ('女高音', 0.954109251499176),\n",
       " ('薇薇安', 0.9537578821182251),\n",
       " ('刀馬旦', 0.9533291459083557),\n",
       " ('李文華', 0.9529095888137817),\n",
       " ('台北', 0.952476441860199),\n",
       " ('馬榮', 0.9520549774169922),\n",
       " ('諧星', 0.9518327713012695),\n",
       " ('相聲', 0.9515189528465271),\n",
       " ('執業', 0.951433539390564),\n",
       " ('真人', 0.9508686065673828),\n",
       " ('滅火器', 0.9508379697799683),\n",
       " ('英傑', 0.9506371021270752),\n",
       " ('柯毓彬', 0.9505053162574768),\n",
       " ('21921687', 0.9503003358840942),\n",
       " ('前麗', 0.9502706527709961),\n",
       " ('姚曉峰', 0.9500453472137451),\n",
       " ('實境秀', 0.9499911665916443),\n",
       " ('脫口秀', 0.9499868154525757),\n",
       " ('唐師曾', 0.9499258995056152),\n",
       " ('授書', 0.9497702121734619),\n",
       " ('葉蒨', 0.9497606754302979),\n",
       " ('奧斯卡獎', 0.9495211839675903),\n",
       " ('慈溪', 0.9494128823280334),\n",
       " ('餘慕蓮', 0.949400007724762),\n",
       " ('開拓者', 0.9492436051368713)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"男歌手\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    return model.wv.vocab[word].index\n",
    "\n",
    "def idx2word(idx):\n",
    "    return model.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 79279, embedding_size: 100\n",
      "Result embedding shape: (79279, 100)\n"
     ]
    }
   ],
   "source": [
    "# 檢視經過訓練出來之後的詞向量\n",
    "pretrained_weights = model.wv.vectors\n",
    "vocab_size, embedding_size = pretrained_weights.shape\n",
    "print(\"vocab_size: {}, embedding_size: {}\".format(vocab_size, embedding_size))\n",
    "print('Result embedding shape:', pretrained_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 構建語言生成 RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide window 用來控制學習的 seq 長度，size 越小，資料量越多，生成的文章會越有語意\n",
    "def slide_window(a, size):\n",
    "    window_list = []\n",
    "    for i in range(len(a)):\n",
    "        window = a[i:size+i]\n",
    "        if len(window) < size:\n",
    "            break\n",
    "        window_list.append(window)\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_x_and_train_y(docs, max_doc_length):\n",
    "    seq_list = []\n",
    "    for doc in docs:\n",
    "        word_index_array = [word2idx(word) for word in doc]\n",
    "        window_list = slide_window(word_index_array, max_doc_length)\n",
    "        for window in window_list:\n",
    "            seq_list.append(window)\n",
    "    seq_list = np.array(seq_list)\n",
    "    train_x = seq_list[:,:-1]\n",
    "    train_y = seq_list[:,-1]\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (79, 99)\n",
      "train_y shape: (79,)\n"
     ]
    }
   ],
   "source": [
    "# 構建訓練資料\n",
    "train_x, train_y = split_train_x_and_train_y(preprocessed_documents, 100)\n",
    "print('train_x shape:', train_x.shape)\n",
    "print('train_y shape:', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14168,  1679,  1973,    14,   262,     3,   120,    12,   503,\n",
       "          17,  6136,     0,   293,  5739,  2702, 48950,  7675,     2,\n",
       "         515,  1706,  6885,     4, 65852,     4,  8903, 11020,     0,\n",
       "        7131,   182,  3755,   639,   489,   136,  2106,     0,  4905,\n",
       "         489,    24,     6,  8903,   785,   143,     0,    31,   596,\n",
       "         346,  1208,  3650,  7131,     0,     5,  2242,    32,  2702,\n",
       "        3650, 32567,   374,     0, 31587,    79,     2,  7296,    24,\n",
       "        7374,  8903,     0,    35,   489,   214, 35316, 25881,     0,\n",
       "        1370,  2702,  3650,  7374,  4250,     2,  2242,    11,   348,\n",
       "         691,   823,    90,     0,    47,   388,   785, 16006,  5739,\n",
       "        8285, 15222,  2242,    15,     0,   348,  3907,  5770,   386])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    print('\\nGenerating text after epoch: %d' % epoch)\n",
    "    texts = [\"施世範\"]\n",
    "    for text in texts:\n",
    "        print('%s... -> %s' % (text, generate_next(texts, 10, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         7927900   \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 79279)             8007179   \n",
      "=================================================================\n",
      "Total params: 16,015,479\n",
      "Trainable params: 8,087,579\n",
      "Non-trainable params: 7,927,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(model.wv.get_keras_embedding())\n",
    "# rnn_model.add(LSTM(embedding_size, dropout=0.5, return_sequences=True))\n",
    "rnn_model.add(LSTM(embedding_size, dropout=0.5))\n",
    "rnn_model.add(Dense(units=vocab_size, activation=\"softmax\"))\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623685 samples, validate on 155922 samples\n",
      "Epoch 1/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 8.0991\n",
      "Generating text after epoch: 0\n",
      "施世範... -> 施世範紂王。被是是在立即他的國家隊\n",
      "Epoch 00000: val_loss improved from inf to 7.61388, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 8.0992 - val_loss: 7.6139\n",
      "Epoch 2/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 7.2856\n",
      "Generating text after epoch: 1\n",
      "施世範... -> 施世範開始2012年月日日，他，在\n",
      "Epoch 00001: val_loss improved from 7.61388 to 7.25977, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 108s - loss: 7.2856 - val_loss: 7.2598\n",
      "Epoch 3/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.9303\n",
      "Generating text after epoch: 2\n",
      "施世範... -> 施世範之在中國足球運動員，於公元前的兒子\n",
      "Epoch 00002: val_loss improved from 7.25977 to 7.06895, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.9301 - val_loss: 7.0690\n",
      "Epoch 4/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.6831\n",
      "Generating text after epoch: 3\n",
      "施世範... -> 施世範的在上海足球俱樂部。與妻子，在\n",
      "Epoch 00003: val_loss improved from 7.06895 to 6.95386, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.6831 - val_loss: 6.9539\n",
      "Epoch 5/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.4877\n",
      "Generating text after epoch: 4\n",
      "施世範... -> 施世範的兒子，即他的兒子，他的\n",
      "Epoch 00004: val_loss improved from 6.95386 to 6.88560, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.4877 - val_loss: 6.8856\n",
      "Epoch 6/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.3281\n",
      "Generating text after epoch: 5\n",
      "施世範... -> 施世範。卡爾王子古斯塔夫阿道夫古斯塔夫古斯塔夫古斯塔夫王子，\n",
      "Epoch 00005: val_loss improved from 6.88560 to 6.83636, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.3281 - val_loss: 6.8364\n",
      "Epoch 7/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.1929\n",
      "Generating text after epoch: 6\n",
      "施世範... -> 施世範，在阿波羅的兒子。後，是中國\n",
      "Epoch 00006: val_loss improved from 6.83636 to 6.80895, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.1929 - val_loss: 6.8090\n",
      "Epoch 8/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 6.0770\n",
      "Generating text after epoch: 7\n",
      "施世範... -> 施世範。被提名的父親的兒子，由香港\n",
      "Epoch 00007: val_loss improved from 6.80895 to 6.78936, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 6.0770 - val_loss: 6.7894\n",
      "Epoch 9/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.9755\n",
      "Generating text after epoch: 8\n",
      "施世範... -> 施世範和挪威。中國國家足球隊國家隊英格蘭。父親的\n",
      "Epoch 00008: val_loss improved from 6.78936 to 6.77732, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.9755 - val_loss: 6.7773\n",
      "Epoch 10/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.8861\n",
      "Generating text after epoch: 9\n",
      "施世範... -> 施世範。阿根廷國家隊主教練。英國下議院，是一位\n",
      "Epoch 00009: val_loss improved from 6.77732 to 6.77372, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.8861 - val_loss: 6.7737\n",
      "Epoch 11/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.8073\n",
      "Generating text after epoch: 10\n",
      "施世範... -> 施世範。人，並且的，其，與鄭成功\n",
      "Epoch 00010: val_loss improved from 6.77372 to 6.77214, saving model to weights.hdf5\n",
      "623685/623685 [==============================] - 109s - loss: 5.8073 - val_loss: 6.7721\n",
      "Epoch 12/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.7380\n",
      "Generating text after epoch: 11\n",
      "施世範... -> 施世範、黃百家，在教皇。在法國的\n",
      "Epoch 00011: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.7381 - val_loss: 6.7753\n",
      "Epoch 13/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.6773\n",
      "Generating text after epoch: 12\n",
      "施世範... -> 施世範。第在荷蘭足球會會西甲。母親\n",
      "Epoch 00012: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.6773 - val_loss: 6.7787\n",
      "Epoch 14/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.6213\n",
      "Generating text after epoch: 13\n",
      "施世範... -> 施世範、陳明宗，在法國數學家，的兒子\n",
      "Epoch 00013: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.6212 - val_loss: 6.7763\n",
      "Epoch 15/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.5721\n",
      "Generating text after epoch: 14\n",
      "施世範... -> 施世範。後，其，在中國足球俱樂部。\n",
      "Epoch 00014: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.5722 - val_loss: 6.7761\n",
      "Epoch 16/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.5268\n",
      "Generating text after epoch: 15\n",
      "施世範... -> 施世範，但是，在加州理工學院，後來在公元，\n",
      "Epoch 00015: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.5268 - val_loss: 6.7861\n",
      "Epoch 17/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4878\n",
      "Generating text after epoch: 16\n",
      "施世範... -> 施世範。成為了的，以時間被抽作。\n",
      "Epoch 00016: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4878 - val_loss: 6.7844\n",
      "Epoch 18/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4500\n",
      "Generating text after epoch: 17\n",
      "施世範... -> 施世範以後，在羅馬皇帝。，是一位在\n",
      "Epoch 00017: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4501 - val_loss: 6.7859\n",
      "Epoch 19/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.4166\n",
      "Generating text after epoch: 18\n",
      "施世範... -> 施世範。日本足球俱樂部和。母親為了，\n",
      "Epoch 00018: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.4166 - val_loss: 6.7973\n",
      "Epoch 20/20\n",
      "623616/623685 [============================>.] - ETA: 0s - loss: 5.3840\n",
      "Generating text after epoch: 19\n",
      "施世範... -> 施世範後，卻去了亞歷山大馬其頓腓力二世的父親\n",
      "Epoch 00019: val_loss did not improve\n",
      "623685/623685 [==============================] - 109s - loss: 5.3841 - val_loss: 6.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3aeab4a4e0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    batch_size=512, \n",
    "    epochs=20, \n",
    "    callbacks=[LambdaCallback(on_epoch_end=on_epoch_end), checkpoint],\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.load_weights(filepath)\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"\n",
    "    temperature 表示控制 sample 字的多樣性，越高越隨機\n",
    "    越低則越強化原本預測機率的差距，ex: [0.2, 0.5, 0.3] -> [0.009, 0.91, 0.07]\n",
    "    \"\"\"\n",
    "    if temperature <= 0:\n",
    "        return np.argmax(preds)\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def generate_next(text, num_generated=10, temperature=1.0):\n",
    "    word_idxs = [word2idx(word) for word in text]\n",
    "    for i in range(num_generated):\n",
    "        prediction = rnn_model.predict(x=np.array(word_idxs))\n",
    "        idx = sample(prediction[-1], temperature)\n",
    "        word_idxs.append(idx)\n",
    "    return ''.join(idx2word(idx) for idx in word_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'呂薇。以為香港足球俱樂部，在巴黎聖日耳曼、張愚，後，被租借，其後，是埃及的父親，在羅馬天主教，在西藏。了一個德國的母親，並，是一名阿根廷，他在2012年，也是先知，他的收入中的女兒。在重慶在2009年，是波斯大流士帝國的。雖然後，以其為了最後的父親愛德華的，現任，在中國國家，在1945，在法國足球俱樂部的兒子。被阮惠之子，以其的中國足球俱樂部位置的，也是法國的行為，後來，為了，他的婚姻，在這支，也是一位意大利的兒子，在羅馬，在日本國家足球隊國家隊，為了。被劃為他在前前前753，同年，是一位的母親陳朝陳煚陳朝，為他的父親是一名生於日本國家足球隊日本職業足球會，在那裡，被殺。出身於前中華人民共和國國務院主席、費拉里，是一位是中國足球俱樂部俱樂部。與馬其頓攝政的父親，被重命名，是他的，立與所羅門王。於中國足球俱樂部，由於被暗殺。成為父親的一個了，後來，被重命名，因後來他被認為是一名，他的，是一名足球會在羅馬皇帝，分別是一個母親，與釋迦牟尼的之後，這在沿海的兒子。在她的，與英國，從美國人，被羅馬皇帝。於2008年，在羅馬皇帝，為新的，曾在英國史密斯，是加州大學洛杉磯分校。了他的兒子。被下啟。在20，以其的，在他們，在耶路撒冷的父親，在倫敦的弟弟，同時是一位前。與中國足球俱樂部上海申花的兒子，後，其，後者是一位的表現是一位是一位是一位著名的弟弟，最後，於中國足球俱樂部，在日本國家足球隊成員。他。他。是一位他的兒子。前，又被吳偉，是一位阿根廷足球俱樂部青訓。父親的兒子。為下，兩人，曾被明命帝，是一位在劍橋大學。與其為了，並與和人。的兒子，在英格蘭的女兒。中國國家足球隊成員。與懷疑的兒子，在他，在耶路撒冷的，是為了的的，為的新。以為。在上海燭龍，以4，是由前前，代表，在其，在以21歲，在這場，率領，以'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隨機生成文章\n",
    "generate_next([idx2word(np.random.randint(vocab_size))], 500, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參考資料\n",
    "1. https://zake7749.github.io/2016/08/28/word2vec-with-gensim/\n",
    "2. https://gist.github.com/maxim5/c35ef2238ae708ccb0e55624e9e0252b\n",
    "3. https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "4. https://www.jianshu.com/p/e19b96908c69"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
