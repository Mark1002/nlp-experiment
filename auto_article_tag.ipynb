{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing plots with style \n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "rcParams['lines.linewidth'] = 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outlier_by_article(df, std_num):\n",
    "    df = df.dropna()\n",
    "    std = df[\"POST_CONTENT\"].str.len().std()\n",
    "    mean = df[\"POST_CONTENT\"].str.len().mean()\n",
    "    upper = mean + std_num*std\n",
    "    return df.loc[df[\"POST_CONTENT\"].str.len()<upper,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_chinese_word(document):\n",
    "# 只取中文\n",
    "    try:\n",
    "        document = \"\".join(re.findall(r\"[\\u4e00-\\u9fa5]+\", document))\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(\"{}, index {}\".format(str(e), index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_document(doc, stop_word_list):\n",
    "    preprocessed_document = jieba.cut(doc)\n",
    "    # 去除保留字\n",
    "    preprocessed_document = list(filter(lambda x: x not in stop_word_list, preprocessed_document))\n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得該群的所有文檔\n",
    "def get_document_by_cluster(corpus, cluster_labels, cluster_id):\n",
    "    cluster_corpus = []\n",
    "    for index, label in enumerate(cluster_labels, 0):\n",
    "        if label == cluster_id:\n",
    "            cluster_corpus.append(corpus[index])\n",
    "    return cluster_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  統計文檔關鍵字\n",
    "def count_doc_word_freq(docs):\n",
    "    word_list = []\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            word_list.append(word)\n",
    "    counter = collections.Counter(word_list)\n",
    "    return counter.most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_tag(test_doc, train_corpus, model, topic_num=10):\n",
    "    # 取得文檔向量\n",
    "    vectors = model.docvecs.vectors_docs\n",
    "    # 分群\n",
    "    k_mean = KMeans(n_clusters=topic_num).fit(vectors)\n",
    "    cluster_labels = k_mean.labels_\n",
    "    # 建立測試向量\n",
    "    doc_vector = model.infer_vector(test_doc).reshape(1,50)\n",
    "    # 分群來去標示主題\n",
    "    cluster_id = int(k_mean.predict(test_doc_vector))\n",
    "    # 取的分群文檔\n",
    "    cluster_docs = get_document_by_cluster(train_corpus, cluster_labels, cluster_id)\n",
    "    # 統計主題，自動取得文章的 tags\n",
    "    term_feq_list = count_doc_word_freq(cluster_docs)\n",
    "    return term_feq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 收集自維基百科\n",
    "with open(\"data/ref_text_tw.txt\", \"r\", encoding=\"utf-8\") as content:\n",
    "    content_list = [line.strip().replace(' ', '') for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Mark1002/Desktop/project/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/dw/m2zgs87j3x19nl8mnfy3fs8c0000gn/T/jieba.ud2b054c4d13e51557150f7d36ba5f4d0.cache\n",
      "Loading model cost 1.697 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current document index:0\n",
      "current document index:2000\n",
      "current document index:4000\n",
      "current document index:6000\n",
      "current document index:8000\n",
      "current document index:10000\n",
      "current document index:12000\n",
      "current document index:14000\n",
      "current document index:16000\n",
      "current document index:18000\n",
      "current document index:20000\n",
      "current document index:22000\n",
      "current document index:24000\n",
      "current document index:26000\n",
      "current document index:28000\n",
      "current document index:30000\n",
      "current document index:32000\n"
     ]
    }
   ],
   "source": [
    "# 用來存放分詞後的結果\n",
    "preprocessed_documents = []\n",
    "# stopword\n",
    "with open(\"data/jieba_dict/stopwords.txt\") as stop_words:\n",
    "    stop_word_list = [stop_word.strip() for stop_word in stop_words]\n",
    "# 支援繁體中文較好的詞庫\n",
    "jieba.set_dictionary(\"data/jieba_dict/dict.txt.big\")\n",
    "jieba.load_userdict(\"data/jieba_dict/中央機構.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/名人錄.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/專有名詞.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/縣市區鄉鎮.dict\")\n",
    "\n",
    "for index, document in enumerate(content_list, 0):\n",
    "    if index % 2000 == 0:\n",
    "        print(\"current document index:{}\".format(index))\n",
    "    document = filter_not_chinese_word(document)\n",
    "    preprocessed_document = tokenize_document(document, stop_word_list)\n",
    "    preprocessed_documents.append(preprocessed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 切分訓練與測試資料集\n",
    "random.shuffle(preprocessed_documents)\n",
    "train_corpus = preprocessed_documents[:int(len(preprocessed_documents)*0.8)]\n",
    "test_corpus = preprocessed_documents[int(len(preprocessed_documents)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set length: 27094, test set length: 6774\n"
     ]
    }
   ],
   "source": [
    "print(\"train set length: {}, test set length: {}\".format(len(train_corpus), len(test_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['年', '慶祝', '新世紀', '到來', '太陽', '王', '路易十四', '法國', '凡爾賽宮', '金碧輝煌', '大廳', '裡', '舉行', '盛大', '舞會', '時', '曾', '身著', '中國式', '服裝', '坐在', '一頂', '中國式', '八擡大轎', '裡', '出場', '全場', '發出', '一片', '驚歎', '聲'], tags=[0]),\n",
       " TaggedDocument(words=['年', '月', '日本', '國家隊', '主教練', '伊維卡', '奧西姆', '腦梗塞', '入院', '搶救', '岡田武史', '再次', '臨危受命', '接替', '奧西姆', '成為', '國家隊', '主教練'], tags=[1]),\n",
       " TaggedDocument(words=['朗奴', '卡達', '連拿馬田', '奧斯禾', '達', '路斯', '荷蘭', '足球', '運動員', '司職', '守門員'], tags=[2]),\n",
       " TaggedDocument(words=['擔任', '羅馬', '國王', '安', '庫斯', '馬', '基', '烏斯', '王子', '監護人', '身份', '國王', '死', '後', '奪取', '王位'], tags=[3]),\n",
       " TaggedDocument(words=['石', '碏', '死後由石', '駘', '仲石祁子', '父子', '相繼', '繼承', '但石', '駘', '仲', '石', '碏', '關係', '不詳', '僅知', '同族', '一說', '石', '碏', '從子', '一說', '石', '碏', '之孫'], tags=[4])]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train doc2vec model\n",
    "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(documents)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:531: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/models/doc2vec.py:535: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# 載入預訓練好的 doc2vec 模型\n",
    "model = Doc2Vec.load(\"data/Doc2Vec_v1.4/d2v.model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分群，每一群代表一個 topic\n",
    "from sklearn.cluster import KMeans\n",
    "# 要定義分群數\n",
    "topic_num = 10\n",
    "vectors = model.docvecs.vectors_docs\n",
    "k_mean = KMeans(n_clusters=topic_num).fit(vectors)\n",
    "cluster_label = k_mean.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1549,\n",
       "         1: 8055,\n",
       "         2: 1638,\n",
       "         3: 1807,\n",
       "         4: 1006,\n",
       "         5: 1668,\n",
       "         6: 3126,\n",
       "         7: 1923,\n",
       "         8: 3935,\n",
       "         9: 2387})"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分群統計\n",
    "collections.Counter(cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立測試向量\n",
    "test_doc_vector = model.infer_vector(test_corpus[1322]).reshape(1, 50)\n",
    "# 分群來去標示主題\n",
    "cluster_result = int(k_mean.predict(test_doc_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 9 群\n"
     ]
    }
   ],
   "source": [
    "print(\"第 {} 群\".format(cluster_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['外界',\n",
       " '辛頓',\n",
       " '印象',\n",
       " '一名',\n",
       " '早熟',\n",
       " '早殘',\n",
       " '球員',\n",
       " '蓋',\n",
       " '早',\n",
       " '年',\n",
       " '已',\n",
       " '當過',\n",
       " '荷蘭',\n",
       " '聯賽',\n",
       " '最佳',\n",
       " '球員',\n",
       " '並於',\n",
       " '年',\n",
       " '世界盃',\n",
       " '後',\n",
       " '轉投',\n",
       " '西甲',\n",
       " '超級',\n",
       " '球會',\n",
       " '巴塞羅那']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[1322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4026, 0.6248799562454224),\n",
       " (11329, 0.5510990619659424),\n",
       " (21162, 0.5127044916152954),\n",
       " (21106, 0.5006772875785828),\n",
       " (25424, 0.4872778058052063),\n",
       " (25924, 0.48405373096466064),\n",
       " (6550, 0.47391277551651),\n",
       " (11439, 0.4514860510826111),\n",
       " (14484, 0.4501854479312897),\n",
       " (9417, 0.44867730140686035)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar(test_doc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['辛頓',\n",
       " '早',\n",
       " '年',\n",
       " '已',\n",
       " '當過',\n",
       " '荷蘭',\n",
       " '聯賽',\n",
       " '最佳',\n",
       " '球員',\n",
       " '參加',\n",
       " '過年',\n",
       " '世界盃',\n",
       " '足球賽',\n",
       " '年',\n",
       " '世界盃',\n",
       " '之後',\n",
       " '加盟',\n",
       " '西甲',\n",
       " '超級',\n",
       " '球會',\n",
       " '巴塞隆',\n",
       " '足球',\n",
       " '巴塞羅那']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[4026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_label[4026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得該群的所有文章\n",
    "cluster_docs = get_document_by_cluster(train_corpus, cluster_label, cluster_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('年', 1095), ('足球', 957), ('運動員', 349), ('日本', 342), ('國家足球隊', 293)]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 統計主題，自動取得文章的 tags\n",
    "count_doc_word_freq(cluster_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('年', 1173), ('足球', 983), ('日本', 378), ('運動員', 360), ('國家足球隊', 325)]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自動取得文章 tag\n",
    "get_topic_tag(test_corpus[1322], train_corpus, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
