{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing plots with style \n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "rcParams['lines.linewidth'] = 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outlier_by_article(df, std_num):\n",
    "    df = df.dropna()\n",
    "    std = df[\"POST_CONTENT\"].str.len().std()\n",
    "    mean = df[\"POST_CONTENT\"].str.len().mean()\n",
    "    upper = mean + std_num*std\n",
    "    return df.loc[df[\"POST_CONTENT\"].str.len()<upper,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_chinese_word(document):\n",
    "# 只取中文\n",
    "    try:\n",
    "        document = \"\".join(re.findall(r\"[\\u4e00-\\u9fa5]+\", document))\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(\"{}\".format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_document(doc, stop_word_list):\n",
    "    preprocessed_document = jieba.cut(doc)\n",
    "    # 去除保留字\n",
    "    preprocessed_document = list(filter(lambda x: x not in stop_word_list, preprocessed_document))\n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  統計文檔關鍵字\n",
    "def count_doc_word_freq(docs):\n",
    "    word_list = []\n",
    "    for doc in docs:\n",
    "        for word in doc:\n",
    "            word_list.append(word)\n",
    "    counter = collections.Counter(word_list)\n",
    "    return counter.most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_tag(docs, d2v_model, classifier, topic_list):\n",
    "    # 確保單一記錄維度預測格式正確\n",
    "    if np.ndim(docs) == 1:\n",
    "        docs = [docs]\n",
    "    # 預測測試資料準確度，使用 infer vector\n",
    "    doc_vector = np.array([d2v_model.infer_vector(doc) for doc in docs])\n",
    "    # 預測測試文章分類\n",
    "    predicted_result = [dict(zip(topic_list, pred)) for pred in np.round(classifier.predict_proba(doc_vector),3)]\n",
    "    return predicted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_tag_tf_idf(docs, tf_idf, classifier, topic_list):\n",
    "    # 確保單一記錄維度預測格式正確\n",
    "    if np.ndim(docs) == 1:\n",
    "        docs = [docs]\n",
    "    docs_tf_idf = convert_tf_idf_corpus(docs)\n",
    "    tf_idf_vector = tf_idf.transform(docs_tf_idf)\n",
    "    # 預測測試文章分類\n",
    "    predicted_result = [dict(zip(topic_list, pred)) for pred in np.round(classifier.predict_proba(tf_idf_vector),3)]\n",
    "    return predicted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_data(raw_docs):\n",
    "    # 用來存放分詞後的結果\n",
    "    preprocessed_documents = []\n",
    "    # stopword\n",
    "    with open(\"data/jieba_dict/stopwords.txt\") as stop_words:\n",
    "        stop_word_list = [stop_word.strip() for stop_word in stop_words]\n",
    "    # 支援繁體中文較好的詞庫\n",
    "    jieba.set_dictionary(\"data/jieba_dict/dict.txt.big\")\n",
    "    jieba.load_userdict(\"data/jieba_dict/中央機構.dict\")\n",
    "    jieba.load_userdict(\"data/jieba_dict/名人錄.dict\")\n",
    "    jieba.load_userdict(\"data/jieba_dict/專有名詞.dict\")\n",
    "    jieba.load_userdict(\"data/jieba_dict/縣市區鄉鎮.dict\")\n",
    "\n",
    "    for index, document in enumerate(raw_docs, 0):\n",
    "        if index % 2000 == 0:\n",
    "            print(\"current document index:{}\".format(index))\n",
    "        # 去除非中文字    \n",
    "        document = filter_not_chinese_word(document)\n",
    "        # 分詞與去掉保留字\n",
    "        document = tokenize_document(document, stop_word_list)\n",
    "        preprocessed_documents.append(document)\n",
    "    return preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_record_by_label(raw_df, num):\n",
    "    temp_df = pd.DataFrame()\n",
    "    raw_df = shuffle(raw_df)\n",
    "    labels = raw_df.groupby('label').size().index.values\n",
    "    for label in labels:\n",
    "        temp_df = temp_df.append(raw_df.loc[raw_df[\"label\"]==label,:].iloc[:num])  \n",
    "    return shuffle(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tf_idf_corpus(corpus):\n",
    "    return [\" \".join(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入不同主題資料\n",
    "topic_list = [\"政治\", \"科技\", \"娛樂\", \"體育\", \"社會\", \"財經\", \"健康\", \"國際\"]\n",
    "raw_df = pd.DataFrame()\n",
    "\n",
    "for index, topic in enumerate(topic_list, 0):\n",
    "    with open(\"data/text/big_data/corpus/\" + topic + \".txt\", \"r\", encoding=\"utf-8\") as content:\n",
    "        content_list = [line.strip().replace(' ', '') for line in content]\n",
    "    temp_df = pd.DataFrame(content_list, columns=['content'])\n",
    "    temp_df['label'] = index\n",
    "    raw_df = raw_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = sample_record_by_label(raw_df, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_df['content'].values\n",
    "y = raw_df['label'].values\n",
    "# 切分訓練與測試\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 18025, 2: 18022, 6: 18021, 4: 18014, 1: 18013, 7: 18003, 5: 17989, 3: 17913})\n",
      "Counter({3: 2087, 5: 2011, 7: 1997, 1: 1987, 4: 1986, 6: 1979, 2: 1978, 0: 1975})\n"
     ]
    }
   ],
   "source": [
    "# 統計各類次數\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Mark1002/Desktop/project/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Dumping model to file cache /var/folders/dw/m2zgs87j3x19nl8mnfy3fs8c0000gn/T/jieba.ud2b054c4d13e51557150f7d36ba5f4d0.cache\n",
      "Loading model cost 3.269 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current document index:0\n",
      "current document index:2000\n",
      "current document index:4000\n",
      "current document index:6000\n",
      "current document index:8000\n",
      "current document index:10000\n",
      "current document index:12000\n",
      "current document index:14000\n",
      "current document index:16000\n",
      "current document index:18000\n",
      "current document index:20000\n",
      "current document index:22000\n",
      "current document index:24000\n",
      "current document index:26000\n",
      "current document index:28000\n",
      "current document index:30000\n",
      "current document index:32000\n",
      "current document index:34000\n",
      "current document index:36000\n",
      "current document index:38000\n",
      "current document index:40000\n",
      "current document index:42000\n",
      "current document index:44000\n",
      "current document index:46000\n",
      "current document index:48000\n",
      "current document index:50000\n",
      "current document index:52000\n",
      "current document index:54000\n",
      "current document index:56000\n",
      "current document index:58000\n",
      "current document index:60000\n",
      "current document index:62000\n",
      "current document index:64000\n",
      "current document index:66000\n",
      "current document index:68000\n",
      "current document index:70000\n",
      "current document index:72000\n",
      "current document index:74000\n",
      "current document index:76000\n",
      "current document index:78000\n",
      "current document index:80000\n",
      "current document index:82000\n",
      "current document index:84000\n",
      "current document index:86000\n",
      "current document index:88000\n",
      "current document index:90000\n",
      "current document index:92000\n",
      "current document index:94000\n",
      "current document index:96000\n",
      "current document index:98000\n",
      "current document index:100000\n",
      "current document index:102000\n",
      "current document index:104000\n",
      "current document index:106000\n",
      "current document index:108000\n",
      "current document index:110000\n",
      "current document index:112000\n",
      "current document index:114000\n",
      "current document index:116000\n",
      "current document index:118000\n",
      "current document index:120000\n",
      "current document index:122000\n",
      "current document index:124000\n",
      "current document index:126000\n",
      "current document index:128000\n",
      "current document index:130000\n",
      "current document index:132000\n",
      "current document index:134000\n",
      "current document index:136000\n",
      "current document index:138000\n",
      "current document index:140000\n",
      "current document index:142000\n"
     ]
    }
   ],
   "source": [
    "X_train_preprocessed = preprocess_text_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Mark1002/Desktop/project/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/dw/m2zgs87j3x19nl8mnfy3fs8c0000gn/T/jieba.ud2b054c4d13e51557150f7d36ba5f4d0.cache\n",
      "Loading model cost 1.637 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current document index:0\n",
      "current document index:2000\n",
      "current document index:4000\n",
      "current document index:6000\n",
      "current document index:8000\n",
      "current document index:10000\n",
      "current document index:12000\n",
      "current document index:14000\n"
     ]
    }
   ],
   "source": [
    "X_test_preprocessed = preprocess_text_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1088c383f9d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train set length: {}, test set length: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_preprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"train set length: {}, test set length: {}\".format(len(X_train_preprocessed), len(X_test_preprocessed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train_preprocessed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train doc2vec model\n",
    "model = Doc2Vec(vector_size=100, window=10, min_count=5, workers=2, epochs=20)\n",
    "model.build_vocab(documents)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"data/model/auto_tag/d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load(\"data/model/auto_tag/d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/model/auto_tag/classifier.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc2vec 文章分類\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# classifier = RandomForestClassifier()\n",
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(d2v_model.docvecs.vectors_docs, y_train)\n",
    "joblib.dump(classifier, 'data/model/auto_tag/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "# load classifier\n",
    "classifier = joblib.load('data/model/auto_tag/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12502083333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 訓練資料準確度\n",
    "train_predict = classifier.predict(d2v_model.docvecs.vectors_docs)\n",
    "accuracy_score(y_train, train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.674125, spend time: -198.08531403541565\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# 預測測試資料準確度，使用 infer vector\n",
    "test_X_vecter = np.array([d2v_model.infer_vector(doc) for doc in X_test_preprocessed]) \n",
    "# 預測測試文章分類\n",
    "test_predict = classifier.predict(test_X_vecter)\n",
    "print(\"acc: {}, spend time: {}\".format(accuracy_score(y_test, test_predict), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.002, 0.036, 0.001, 0.007, 0.001, 0.786, 0.04 , 0.129]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(classifier.predict_proba(d2v_model.docvecs.vectors_docs[:1]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('健康',\n",
       " '好醫師新聞網記者邊建元／台東報導圖：台東馬偕直腸外科洪毓廷醫師俗語說「十男九痔，有痔瘡的女人也不少」，可見痔瘡是個非常普遍的惱人隱疾。一位收容人，自行以釣魚線綁在痔瘡上，因疼痛難耐被送來就醫，檢查時痔瘡已嚴重腫脹壞死，已無法以藥物治療，必須開刀切除才痊癒。台東馬偕直腸外科洪毓廷呼籲，民眾若有肛門相關問題，包括會痛、會流血或滲液、會癢，都應尋找專科醫師檢查治療，不應自行尋求偏方以免延誤治療。雖然痔瘡與癌症無關，但臨床上常因懷疑是痔瘡卻查出更多複雜的疾病，甚至是癌症，不可不慎。台東馬偕的毓廷是台東唯一的直腸外科醫師。他說，痔瘡的功能就好像是水龍頭裡的橡皮墊，控制直腸內的氣體和液體，若平日排便習慣不佳、肛門血管循環變差，易造成痔瘡問題。在門診的個案中，有一半都是來看痔瘡疾病，病人都是因為患部持續流血、疼痛或造成身體不適才會就醫。這種疾病不分族群不分年齡，但女性因經歷懷孕生產，所以罹患比率高於男性；職業上則以粗重工作及長期坐辦公室居多，可能伴隨人一輩子，許多人則與它和平共處。洪毓廷指出，痔瘡一般分為「內痔」、「外痔」、「混合痔」，通常會痛的都是外痔發作。痔瘡也依脫出的程度可分為四度，一般來說大部分的痔瘡採取局部藥物塗抹治療即能有效控制症狀，若有以下三個狀況該考慮開刀，一是頻繁無法控制的出血，二是反覆的發作或是嚴重的疼痛無法被改善，再來是持續的脫出或是異物感，治療的選擇建議與專科醫師做詳細的討論。外科方法的治療包括橡皮筋結紮術，電燒，雷射或冷凍治療，超音波導引肛門血管結紮術，環狀切除術，微創痔瘡切除術及傳統的內外至全切除手術，一般而言痔瘡切除後並不會造成肛門失禁，手術後一週間常會因疼痛或感覺異常造成不同程度的排便困難或是輕微水便失禁等情形，而老人家肛門肌肉較鬆弛容易在手術後有肛門關不住的感覺，至於手術方法的選擇應諮詢專業醫師的建議。洪醫師也進一步提出痔瘡的預防及保健，電視上廣告中所提的「不要坐太久、天天有蔬果、少辣少油炸、飯後走一走」，雖然洗腦卻是要落實在生活中。另外，現今３C產品充斥生活，很多人常帶手機進廁所，一待待半小時，過於擠壓肛門會使痔瘡惡化，建議上廁所時間不要超過十分鐘。痔瘡患者常常會有解不乾淨的感覺，這是因為蹲坐時間太長導致痔瘡腫脹，感覺上會以為是還沒解乾淨，如果再持續用力就會把痔瘡擠出肛門，造成急性血栓性痔瘡。如果有這種情形，建議離開廁所走一走休息一下，一般便意就會因為痔瘡消腫而消失。男性更年期要養氣首重補肝、養腎、固元氣胸椎骨折免忍痛骨水泥三天出院佛系醫院送健檢46員工發現肺部節結3D列印義肢足踝變膝蓋驚！三高死亡人數比癌症多3.5倍')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試資料\n",
    "(topic_list[y_test[22]], X_test[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 tf-idf 來分類\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換 tf-idf 格式\n",
    "# X_train_tf_idf = convert_tf_idf_corpus(X_train_preprocessed)\n",
    "X_test_tf_idf = convert_tf_idf_corpus(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 tf-idf 模型\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2)\n",
    "tfidf = vectorizer.fit(X_train_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/model/auto_tag/tf-idf.pkl']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'data/model/auto_tag/tf-idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "tfidf = joblib.load('data/model/auto_tag/tf-idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉換 tf-idf 特徵\n",
    "# X_train_tf_idf_feature = tfidf.transform(X_train_tf_idf)\n",
    "X_test_tf_idf_feature = tfidf.transform(X_test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 326567)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tf_idf_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326567"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(X_train_tf_idf_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/model/auto_tag/tf-idf-classifier.pkl']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, 'data/model/auto_tag/tf-idf-classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier\n",
    "tf_idf_classifier = joblib.load('data/model/auto_tag/tf-idf-classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8942222222222223"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 訓練資料準確度\n",
    "train_predict = tf_idf_classifier.predict(X_train_tf_idf_feature)\n",
    "accuracy_score(y_train, train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8885, spend time: 0.07359504699707031\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "test_predict = tf_idf_classifier.predict(X_test_tf_idf_feature)\n",
    "print(\"acc: {}, spend time: {}\".format(accuracy_score(y_test, test_predict), time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<407x326567 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 363 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.transform(X_test_preprocessed[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['好',\n",
       " '醫師',\n",
       " '新聞網',\n",
       " '記者',\n",
       " '建元',\n",
       " '台東',\n",
       " '報導',\n",
       " '圖台',\n",
       " '東馬',\n",
       " '偕',\n",
       " '直腸',\n",
       " '外科',\n",
       " '洪毓廷',\n",
       " '醫師',\n",
       " '俗語說',\n",
       " '十男',\n",
       " '痔',\n",
       " '痔瘡',\n",
       " '女人',\n",
       " '痔瘡',\n",
       " '普遍',\n",
       " '惱人',\n",
       " '隱疾',\n",
       " '一位',\n",
       " '收容',\n",
       " '人',\n",
       " '自行',\n",
       " '釣魚',\n",
       " '線',\n",
       " '綁',\n",
       " '痔瘡',\n",
       " '疼痛',\n",
       " '難耐',\n",
       " '送來',\n",
       " '就醫',\n",
       " '檢查',\n",
       " '時',\n",
       " '痔瘡',\n",
       " '已',\n",
       " '嚴重',\n",
       " '腫脹',\n",
       " '壞死',\n",
       " '已',\n",
       " '無法',\n",
       " '藥物',\n",
       " '治療',\n",
       " '開刀',\n",
       " '切除',\n",
       " '痊癒',\n",
       " '台',\n",
       " '東馬',\n",
       " '偕',\n",
       " '直腸',\n",
       " '外科',\n",
       " '洪毓廷',\n",
       " '呼籲',\n",
       " '民眾',\n",
       " '肛門',\n",
       " '相關',\n",
       " '問題',\n",
       " '包括',\n",
       " '痛會',\n",
       " '流血',\n",
       " '滲液',\n",
       " '癢',\n",
       " '應',\n",
       " '尋找',\n",
       " '專科',\n",
       " '醫師',\n",
       " '檢查',\n",
       " '治療',\n",
       " '應',\n",
       " '自行',\n",
       " '尋求',\n",
       " '偏方',\n",
       " '延誤',\n",
       " '治療',\n",
       " '痔瘡',\n",
       " '癌症',\n",
       " '無關',\n",
       " '但臨',\n",
       " '床上',\n",
       " '常因',\n",
       " '懷疑',\n",
       " '痔瘡',\n",
       " '卻',\n",
       " '查出',\n",
       " '複雜',\n",
       " '疾病',\n",
       " '癌症',\n",
       " '不可',\n",
       " '不慎',\n",
       " '台',\n",
       " '東馬',\n",
       " '偕',\n",
       " '毓',\n",
       " '廷',\n",
       " '台東',\n",
       " '唯一',\n",
       " '直腸',\n",
       " '外科',\n",
       " '醫師',\n",
       " '說',\n",
       " '痔瘡',\n",
       " '功能',\n",
       " '好像',\n",
       " '水龍頭',\n",
       " '裡的',\n",
       " '橡皮',\n",
       " '墊',\n",
       " '控制',\n",
       " '直腸',\n",
       " '氣體',\n",
       " '液體',\n",
       " '平日',\n",
       " '排便',\n",
       " '習慣',\n",
       " '不佳',\n",
       " '肛門',\n",
       " '血管',\n",
       " '循環',\n",
       " '變差',\n",
       " '易',\n",
       " '造成',\n",
       " '痔瘡',\n",
       " '問題',\n",
       " '門診',\n",
       " '個案',\n",
       " '中有',\n",
       " '一半',\n",
       " '痔瘡',\n",
       " '疾病',\n",
       " '病人',\n",
       " '患部',\n",
       " '持續',\n",
       " '流血',\n",
       " '疼痛',\n",
       " '造成',\n",
       " '身體',\n",
       " '適才',\n",
       " '就醫',\n",
       " '這種',\n",
       " '疾病',\n",
       " '分',\n",
       " '族群',\n",
       " '分',\n",
       " '年齡',\n",
       " '女性',\n",
       " '經歷',\n",
       " '懷孕',\n",
       " '生產',\n",
       " '罹患',\n",
       " '比率',\n",
       " '高於',\n",
       " '男性',\n",
       " '職業',\n",
       " '上則',\n",
       " '粗重',\n",
       " '工作',\n",
       " '長期',\n",
       " '坐',\n",
       " '辦公室',\n",
       " '居多',\n",
       " '伴隨',\n",
       " '人',\n",
       " '一輩子',\n",
       " '許多',\n",
       " '人則',\n",
       " '和平共處',\n",
       " '洪毓廷',\n",
       " '指出',\n",
       " '痔瘡',\n",
       " '分為',\n",
       " '內痔',\n",
       " '外痔',\n",
       " '混合',\n",
       " '痔',\n",
       " '通常',\n",
       " '會痛',\n",
       " '外痔',\n",
       " '發作',\n",
       " '痔瘡',\n",
       " '脫出',\n",
       " '程度',\n",
       " '可分',\n",
       " '四度',\n",
       " '一般來說',\n",
       " '大部分',\n",
       " '痔瘡',\n",
       " '採取',\n",
       " '局部',\n",
       " '藥物',\n",
       " '塗抹',\n",
       " '治療',\n",
       " '即能',\n",
       " '有效',\n",
       " '控制',\n",
       " '症狀',\n",
       " '若有',\n",
       " '以下',\n",
       " '三個',\n",
       " '狀況',\n",
       " '考慮',\n",
       " '開刀',\n",
       " '一是',\n",
       " '頻繁',\n",
       " '無法控制',\n",
       " '出血',\n",
       " '二是',\n",
       " '反覆',\n",
       " '發作',\n",
       " '嚴重',\n",
       " '疼痛',\n",
       " '無法',\n",
       " '改善',\n",
       " '再來',\n",
       " '持續',\n",
       " '脫出',\n",
       " '異物感',\n",
       " '治療',\n",
       " '選擇',\n",
       " '建議',\n",
       " '專科',\n",
       " '醫師',\n",
       " '做',\n",
       " '詳細',\n",
       " '討論',\n",
       " '外科',\n",
       " '方法',\n",
       " '治療',\n",
       " '包括',\n",
       " '橡皮筋',\n",
       " '結紮術',\n",
       " '電燒',\n",
       " '雷射',\n",
       " '冷凍',\n",
       " '治療',\n",
       " '超音波',\n",
       " '導引',\n",
       " '肛門',\n",
       " '血管',\n",
       " '結紮術',\n",
       " '環狀',\n",
       " '切除術',\n",
       " '微創',\n",
       " '痔瘡',\n",
       " '切除術',\n",
       " '傳統',\n",
       " '內外',\n",
       " '至全',\n",
       " '切除',\n",
       " '手術',\n",
       " '一般而言',\n",
       " '痔瘡',\n",
       " '切除',\n",
       " '後並',\n",
       " '造成',\n",
       " '肛門',\n",
       " '失禁',\n",
       " '手術',\n",
       " '後',\n",
       " '一週',\n",
       " '間',\n",
       " '常會',\n",
       " '疼痛',\n",
       " '感覺',\n",
       " '異常',\n",
       " '造成',\n",
       " '程度',\n",
       " '排便',\n",
       " '困難',\n",
       " '輕微',\n",
       " '水便',\n",
       " '失禁',\n",
       " '情形',\n",
       " '老人家',\n",
       " '肛門',\n",
       " '肌肉',\n",
       " '鬆弛',\n",
       " '容易',\n",
       " '手術',\n",
       " '後',\n",
       " '肛門',\n",
       " '關不住',\n",
       " '感覺',\n",
       " '手術',\n",
       " '方法',\n",
       " '選擇',\n",
       " '應',\n",
       " '諮詢',\n",
       " '專業',\n",
       " '醫師',\n",
       " '建議',\n",
       " '洪',\n",
       " '醫師',\n",
       " '進一步',\n",
       " '提出',\n",
       " '痔瘡',\n",
       " '預防',\n",
       " '保健',\n",
       " '電視',\n",
       " '廣告',\n",
       " '中所提',\n",
       " '坐',\n",
       " '太久',\n",
       " '天天',\n",
       " '蔬果',\n",
       " '少辣少',\n",
       " '油炸',\n",
       " '飯後',\n",
       " '走',\n",
       " '走',\n",
       " '洗腦',\n",
       " '卻是',\n",
       " '落實',\n",
       " '在生活中',\n",
       " '現今',\n",
       " '產品',\n",
       " '充斥',\n",
       " '生活',\n",
       " '人常帶',\n",
       " '手機',\n",
       " '進',\n",
       " '廁所',\n",
       " '一待待',\n",
       " '半小時',\n",
       " '擠壓',\n",
       " '肛門',\n",
       " '使',\n",
       " '痔瘡',\n",
       " '惡化',\n",
       " '建議',\n",
       " '廁所',\n",
       " '時間',\n",
       " '超過',\n",
       " '十分鐘',\n",
       " '痔瘡',\n",
       " '患者',\n",
       " '有解',\n",
       " '乾淨',\n",
       " '感覺',\n",
       " '這是',\n",
       " '蹲坐',\n",
       " '時間',\n",
       " '太長',\n",
       " '導致',\n",
       " '痔瘡',\n",
       " '腫脹',\n",
       " '感覺',\n",
       " '上會',\n",
       " '還沒解',\n",
       " '乾淨',\n",
       " '再',\n",
       " '持續',\n",
       " '用力',\n",
       " '痔瘡',\n",
       " '擠出',\n",
       " '肛門',\n",
       " '造成',\n",
       " '急性',\n",
       " '血栓性',\n",
       " '痔瘡',\n",
       " '這種',\n",
       " '情形',\n",
       " '建議',\n",
       " '離開',\n",
       " '廁所',\n",
       " '走',\n",
       " '走',\n",
       " '休息',\n",
       " '一下',\n",
       " '便意',\n",
       " '痔瘡',\n",
       " '消腫',\n",
       " '消失',\n",
       " '男性',\n",
       " '更年期',\n",
       " '養氣',\n",
       " '首重',\n",
       " '補肝養',\n",
       " '腎固',\n",
       " '元氣',\n",
       " '胸椎',\n",
       " '骨折',\n",
       " '免',\n",
       " '忍痛',\n",
       " '骨',\n",
       " '水泥',\n",
       " '三天',\n",
       " '出院',\n",
       " '佛系',\n",
       " '醫院',\n",
       " '送健檢',\n",
       " '員工',\n",
       " '發現',\n",
       " '肺部',\n",
       " '節結',\n",
       " '列印',\n",
       " '義肢',\n",
       " '足踝',\n",
       " '變',\n",
       " '膝蓋',\n",
       " '驚三高',\n",
       " '死亡',\n",
       " '人數',\n",
       " '癌症',\n",
       " '多倍']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preprocessed[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'健康': 0.946,\n",
       "  '國際': 0.013,\n",
       "  '娛樂': 0.004,\n",
       "  '政治': 0.005,\n",
       "  '社會': 0.02,\n",
       "  '科技': 0.004,\n",
       "  '財經': 0.005,\n",
       "  '體育': 0.003}]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic_tag_tf_idf(X_test_preprocessed[22], tfidf, classifier, topic_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
