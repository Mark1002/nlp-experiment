{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing plots with style \n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "rcParams['lines.linewidth'] = 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 給一個關鍵字 tag，並從中找到相像關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入\n",
    "# 回文\n",
    "comment_data = pd.read_csv(\"data/big_data/楊俊瀚_comment_0.csv\", usecols=[\"POST_TITLE\", \"POST_CONTENT\"], encoding=\"utf8\")\n",
    "# 主文\n",
    "post_data = pd.read_csv(\"data/big_data/楊俊瀚_post_0.csv\", usecols=[\"POST_TITLE\", \"POST_CONTENT\"], encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101000, 2)\n",
      "(101, 2)\n"
     ]
    }
   ],
   "source": [
    "print(comment_data.shape)\n",
    "print(post_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    8137\n",
       "46     1234\n",
       "49     1184\n",
       "99     1118\n",
       "96     1113\n",
       "50     1070\n",
       "47     1067\n",
       "27     1041\n",
       "48     1032\n",
       "81     1023\n",
       "Name: POST_CONTENT, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 主文長度排序\n",
    "post_data[\"POST_CONTENT\"].str.len().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47002    164\n",
       "46001    164\n",
       "2010     164\n",
       "68111    164\n",
       "43041    164\n",
       "41130    164\n",
       "1043     164\n",
       "348      164\n",
       "7677     160\n",
       "23632    160\n",
       "Name: POST_CONTENT, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評論長度排序\n",
    "comment_data[\"POST_CONTENT\"].str.len().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outlier_by_article(df, std_num):\n",
    "    df = df.dropna()\n",
    "    std = df[\"POST_CONTENT\"].str.len().std()\n",
    "    mean = df[\"POST_CONTENT\"].str.len().mean()\n",
    "    upper = mean + std_num*std\n",
    "    return df.loc[df[\"POST_CONTENT\"].str.len()<upper,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post data length: 100, comment data length: 100279\n"
     ]
    }
   ],
   "source": [
    "# 刪除離群值文本記錄\n",
    "post_data = filter_outlier_by_article(post_data, 1)\n",
    "comment_data = filter_outlier_by_article(comment_data, 1)\n",
    "print(\"post data length: {}, comment data length: {}\".format(len(post_data), len(comment_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data = comment_data.loc[comment_data[\"POST_TITLE\"].str.contains(\"楊俊瀚\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = post_data.append(comment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理\n",
    "raw_data = raw_data.dropna()\n",
    "content_list = raw_data[\"POST_CONTENT\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26014"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['可惜了',\n",
       " '「銀」得可惜！我田徑好手楊俊瀚在雅加達亞運男子兩百公尺拿下銀牌，雖然成績與金牌得主日本選手小池祐貴同為廿秒二三，但經電腦判定落敗，楊俊瀚自認做到九十九分，「如果再好一點點，或許我就是以千分之一贏的那一個。」楊俊瀚激動落淚哭完說：上天給的結果楊俊瀚起跑出彎道後一度領先，但隔壁跑道的小池祐貴追上並列，雙方纏鬥到終點線，最終透過影像判定，算到小數點後三位才落敗，楊俊瀚激動落淚，不過哭完就恢復心情，他說：「如果有一點差距，代表我們不夠努力，輸千分位，就是上天給的結果。」等了64年我第一面男子200公尺獎牌楊俊瀚的教練陶武訓在一九九四年廣島亞運曾跑出第四名佳績，這次楊完成賽前向教練說「目標至少要打破你」的宣言，拿下中華隊自參加亞運以來，等了六十四年的第一面男子兩百公尺獎牌。但楊俊瀚卻心情複雜，「我辦到了，但只是九十九分，為什麼不做到一百分？」「如果再好一點點，或許我就是贏的那個」差了哪一分？楊俊瀚說：「如果心理調適再好一點、休息再好一點，什麼都能做好一點點，說不定我是贏他千分位的那一個。」楊俊瀚透露比賽前一天失眠，整晚幾乎沒睡，一路焦慮到賽前熱身。教練告訴楊俊瀚：「再怎麼準備也達不到百分百，不如把握好現在的狀態。」他雖然聽見了，卻進不到心裡，直到想起去年世大運也是狀況不好，最後在一百公尺破全國紀錄，楊俊瀚說：「當下心情就舒坦了，應該要相信教練。」加上楊俊瀚這面銀牌，中華代表團昨天總計進帳三銀一銅，黃亭茵在自由車個人全能賽摘銀，鄭竹玲在軟網女單不敵日本女將高橋乃綾拿下銀牌，楊勇緯則在柔道男子六十公斤級從敗部復活奪銅；中華拳擊女將林郁婷則逆轉打進四強，至少銅牌起跳。',\n",
       " '我國100公尺全國紀錄保持人楊俊瀚，26日晚間9點25出賽100公尺決賽，跑出和準決賽同樣的10秒17最終排名第五無緣獎牌，金牌則是跑出9秒92破大會的中國蘇炳添。100公尺預賽階段，楊俊瀚跑出10秒13列在分組第一，同時也是預賽第一、順利晉級下一輪，來到準決賽，楊俊瀚雖然開跑時稍微落後，不過後段加速，跑出10秒17分組第二、準決賽第三順利闖進決賽。決賽階段，楊俊瀚再度跑出10秒17，蘇炳添以9秒92摘金，卡達TosinOgunode跑出10秒00排第二，日本的山縣亮太則以同樣秒數排第三楊俊瀚去年在全大運、台北世大運先後刷新我國100公尺紀錄，接著今年的日本大學公開賽，先在資格賽中飆出10秒18，接著又在決賽跑出10秒11，兩度刷新全國紀錄，來到亞運後維持極佳狀態，預賽、準決賽都維持在水準，可惜決賽未能再突破，以10秒17排第五，但沒關係，楊俊瀚接下來還有200公尺，將持續挑戰為中華奪牌。',\n",
       " '蔡英文昨天又在消費楊俊瀚兩百公尺決賽差0.001秒金牌但因為奪金的是日本國(吱吱的祖國)蔡英文就反而安撫國人不要計較運動精神就是金牌如果今天同時壓線的選手是中國大陸蔡英文可能已經動用媒體民嘴大罵亞運不公蔡英文應該向楊俊瀚道歉',\n",
       " '各位覺青大家好，剛剛我在日本網站上看到有不少日本人在比較他們的新科亞運銅牌山縣亮太，和臺灣百米飛人楊俊瀚誰顏值比較高有沒有臺日百米飛人--楊俊瀚VS.山縣亮太誰比較帥的八卦']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = [doc.strip().replace(' ', '') for doc in content_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定濾掉的詞性，並過濾掉其他詞\n",
    "def filter_part_speech(pos_list, part_speech_list):\n",
    "    return list(filter(lambda x: x.flag not in pos_list, part_speech_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_not_chinese_word(document):\n",
    "# 只取中文\n",
    "    try:\n",
    "        document = \"\".join(re.findall(r\"[\\u4e00-\\u9fa5]+\", document))\n",
    "        return document\n",
    "    except Exception as e:\n",
    "        print(\"{}, index {}\".format(str(e), index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_document(doc, stop_word_list):\n",
    "    preprocessed_document = jieba.cut(doc)\n",
    "    # 去除保留字\n",
    "    preprocessed_document = list(filter(lambda x: x not in stop_word_list, preprocessed_document))\n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用 pos 會超慢\n",
    "def tokenize_document_by_pos(doc, stop_word_list, filter_pos):\n",
    "    part_speech_list = pseg.cut(doc)\n",
    "    # 去除保留字\n",
    "    part_speech_list = list(filter(lambda x: x.word not in stop_word_list, part_speech_list))\n",
    "    # 篩選字詞 ['n', 'x', 'n', 'ng', 'nr', 'ns']\n",
    "    part_speech_list = filter_part_speech(filter_pos, part_speech_list)\n",
    "    preprocessed_document = [part_speech.word for part_speech in part_speech_list]\n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/Mark1002/Desktop/project/python/nlp-experiment/data/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/dw/m2zgs87j3x19nl8mnfy3fs8c0000gn/T/jieba.ud2b054c4d13e51557150f7d36ba5f4d0.cache\n",
      "Loading model cost 1.448 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current document index:0\n",
      "current document index:2000\n",
      "current document index:4000\n",
      "current document index:6000\n",
      "current document index:8000\n",
      "current document index:10000\n",
      "current document index:12000\n",
      "current document index:14000\n",
      "current document index:16000\n",
      "current document index:18000\n",
      "current document index:20000\n",
      "current document index:22000\n",
      "current document index:24000\n",
      "current document index:26000\n"
     ]
    }
   ],
   "source": [
    "# 用來存放分詞後的結果\n",
    "preprocessed_documents = []\n",
    "# stopword\n",
    "with open(\"data/jieba_dict/stopwords.txt\") as stop_words:\n",
    "    stop_word_list = [stop_word.strip() for stop_word in stop_words]\n",
    "# 支援繁體中文較好的詞庫\n",
    "jieba.set_dictionary(\"data/jieba_dict/dict.txt.big\")\n",
    "jieba.load_userdict(\"data/jieba_dict/中央機構.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/名人錄.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/專有名詞.dict\")\n",
    "jieba.load_userdict(\"data/jieba_dict/縣市區鄉鎮.dict\")\n",
    "\n",
    "for index, document in enumerate(content_list, 0):\n",
    "    if index % 2000 == 0:\n",
    "        print(\"current document index:{}\".format(index))\n",
    "    # 只取中文    \n",
    "    document = filter_not_chinese_word(document)\n",
    "    # preprocessed_document = tokenize_document_by_pos(document, stop_word_list, ['n', 'x', 'n', 'ng', 'nr', 'ns'])\n",
    "    preprocessed_document = tokenize_document(document, stop_word_list)\n",
    "    preprocessed_documents.append(preprocessed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['楊',\n",
       " '肩膀',\n",
       " '先過',\n",
       " '規則',\n",
       " '運動員',\n",
       " '抵達',\n",
       " '終點',\n",
       " '名次',\n",
       " '時應',\n",
       " '軀幹',\n",
       " '包括',\n",
       " '頭頸',\n",
       " '臂手',\n",
       " '腿',\n",
       " '腳',\n",
       " '部分',\n",
       " '到達',\n",
       " '終點']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_documents[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872282, 1030490)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    preprocessed_documents, \n",
    "    size=250,\n",
    "    min_count=3, \n",
    "    window=10,\n",
    ")\n",
    "model.train(preprocessed_documents, total_examples=len(preprocessed_documents), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('紀錄', 0.8223675489425659),\n",
       " ('生涯', 0.7949206829071045),\n",
       " ('一口氣', 0.7843143939971924),\n",
       " ('繳出', 0.7825567722320557),\n",
       " ('卡達', 0.771132230758667),\n",
       " ('突破', 0.7706197500228882),\n",
       " ('超扯', 0.7374297380447388),\n",
       " ('全國紀錄', 0.7365154027938843),\n",
       " ('曼谷', 0.7339699268341064),\n",
       " ('打破', 0.7331404089927673)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"最佳\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('要拿牌', 0.8486579656600952),\n",
       " ('第一名', 0.8454180955886841),\n",
       " ('破紀錄', 0.8288664817810059),\n",
       " ('逮丸隊', 0.8156543970108032),\n",
       " ('栽培', 0.8140100240707397),\n",
       " ('改善', 0.8105578422546387),\n",
       " ('節奏', 0.7979242205619812),\n",
       " ('抓好', 0.7961492538452148),\n",
       " ('共識', 0.7950407266616821),\n",
       " ('那間', 0.7841838598251343)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"夠強\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入預訓練好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入預訓練好的模型\n",
    "wv_from_bin = Word2Vec.load(\"data/Word2Vec_v1.4/w2v.model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark1002/anaconda/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "expansion_list = wv_from_bin.wv.most_similar(\"喜歡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['討厭', '我喜歡', '不喜歡', '很愛', '喜歡的', '有魅力', '不愛', '鍾愛', '愛看', '喜歡你']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word, points in expansion_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料集規模就是一切"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
